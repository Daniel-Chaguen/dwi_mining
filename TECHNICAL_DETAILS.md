# ğŸ”¬ Technical Details - DWI Mining Project

Este documento proporciona detalles tÃ©cnicos profundos sobre las metodologÃ­as, arquitecturas y decisiones de diseÃ±o del proyecto.

---

## ğŸ“ Feature Engineering: FA Block Extraction

### Fractional Anisotropy (FA) Mathematics

La **AnisotropÃ­a Fraccional** es una mÃ©trica derivada del tensor de difusiÃ³n que cuantifica la direccionalidad de la difusiÃ³n del agua en tejido cerebral.

#### Paso 1: EstimaciÃ³n del Tensor de DifusiÃ³n

El tensor de difusiÃ³n **D** es una matriz simÃ©trica 3Ã—3 que describe cÃ³mo las molÃ©culas de agua se difunden en el espacio:

$$
D = \begin{bmatrix}
D_{xx} & D_{xy} & D_{xz} \\
D_{xy} & D_{yy} & D_{yz} \\
D_{xz} & D_{yz} & D_{zz}
\end{bmatrix}
$$

Se obtiene ajustando el modelo DTI a los datos DWI mediante:

$$
S(\mathbf{b}, \mathbf{g}) = S_0 \exp\left(-b \, \mathbf{g}^T D \mathbf{g}\right)
$$

Donde:
- $S(\mathbf{b}, \mathbf{g})$ = intensidad medida con gradiente $\mathbf{g}$ y valor b
- $S_0$ = imagen sin gradiente de difusiÃ³n (b0)
- $b$ = factor de ponderaciÃ³n de difusiÃ³n (b-value)
- $\mathbf{g}$ = vector unitario de direcciÃ³n del gradiente

#### Paso 2: DescomposiciÃ³n Espectral

El tensor se descompone en autovalores y autovectores:

$$
D = V \Lambda V^{-1}
$$

Donde:
- $\Lambda = \text{diag}(\lambda_1, \lambda_2, \lambda_3)$ con $\lambda_1 \geq \lambda_2 \geq \lambda_3$
- $\lambda_1$ = difusiÃ³n mÃ¡xima (direcciÃ³n principal de fibras)
- $\lambda_2, \lambda_3$ = difusiÃ³n perpendicular

#### Paso 3: CÃ¡lculo de FA

$$
FA = \sqrt{\frac{3}{2}} \frac{\sqrt{(\lambda_1 - \bar{\lambda})^2 + (\lambda_2 - \bar{\lambda})^2 + (\lambda_3 - \bar{\lambda})^2}}{\sqrt{\lambda_1^2 + \lambda_2^2 + \lambda_3^2}}
$$

Donde $\bar{\lambda} = \frac{\lambda_1 + \lambda_2 + \lambda_3}{3}$ es la difusividad media.

**InterpretaciÃ³n:**
- **FA = 0**: DifusiÃ³n isotrÃ³pica (lÃ­quido cefalorraquÃ­deo, sustancia gris)
- **FA = 1**: DifusiÃ³n perfectamente direccional (fibras de sustancia blanca bien organizadas)
- **Rango tÃ­pico en cerebro**: 0.2 - 0.8

### Block Aggregation Strategy

En lugar de usar todos los 4,608,000 voxels (96 Ã— 96 Ã— 50) como features, implementamos agregaciÃ³n por bloques:

1. **DivisiÃ³n espacial**: Crear grid 3D de 8Ã—8Ã—8 = **512 bloques**
2. **AgregaciÃ³n local**: Calcular $\bar{FA}_{\text{block}} = \frac{1}{N} \sum_{v \in \text{block}} FA(v)$
3. **Resultado**: Vector de 512 features por sujeto

**Ventajas:**
- âœ… Reduce dimensionalidad 9000Ã— (4.6M â†’ 512)
- âœ… Robustez ante ruido voxel-wise
- âœ… Preserva informaciÃ³n espacial regional
- âœ… Compatible con modelos clÃ¡sicos (SVM, XGBoost)

---

## ğŸ§  3D CNN Architecture Deep Dive

### ImprovedCNN3D Architecture

```
Input: (Batch, 64, 50, 96, 96)
       [B, Channels, Depth, Height, Width]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Block 1: Feature Extraction                     â”‚
â”‚   Conv3D(64â†’32, k=3, s=1, p=1)                  â”‚
â”‚   BatchNorm3D(32)                               â”‚
â”‚   ReLU(inplace=True)                            â”‚
â”‚   Dropout3D(p=0.1)                              â”‚
â”‚ Output: (B, 32, 50, 96, 96)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Block 2: Spatial Reduction                      â”‚
â”‚   Conv3D(32â†’64, k=3, s=1, p=1)                  â”‚
â”‚   BatchNorm3D(64)                               â”‚
â”‚   ReLU(inplace=True)                            â”‚
â”‚   MaxPool3D(k=2, s=2)                           â”‚
â”‚   Dropout3D(p=0.1)                              â”‚
â”‚ Output: (B, 64, 25, 48, 48)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Block 3: High-Level Features                    â”‚
â”‚   Conv3D(64â†’128, k=3, s=1, p=1)                 â”‚
â”‚   BatchNorm3D(128)                              â”‚
â”‚   ReLU(inplace=True)                            â”‚
â”‚   MaxPool3D(k=2, s=2)                           â”‚
â”‚   Dropout3D(p=0.1)                              â”‚
â”‚ Output: (B, 128, 12, 24, 24)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Block 4: Abstract Representations               â”‚
â”‚   Conv3D(128â†’256, k=3, s=1, p=1)                â”‚
â”‚   BatchNorm3D(256)                              â”‚
â”‚   ReLU(inplace=True)                            â”‚
â”‚   Dropout3D(p=0.1)                              â”‚
â”‚ Output: (B, 256, 12, 24, 24)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Global Pooling                                  â”‚
â”‚   AdaptiveAvgPool3D(output_size=1)              â”‚
â”‚ Output: (B, 256, 1, 1, 1)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Classifier                                      â”‚
â”‚   Flatten â†’ (B, 256)                            â”‚
â”‚   Linear(256 â†’ 128)                             â”‚
â”‚   ReLU(inplace=True)                            â”‚
â”‚   Dropout(p=0.2)                                â”‚
â”‚   Linear(128 â†’ 2)                               â”‚
â”‚ Output: (B, 2) [Control, Patient]               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Design Decisions

#### 1. Input Channel Handling
**DecisiÃ³n**: Eliminar canal b0, usar solo 64 canales de difusiÃ³n

**RazÃ³n**: 
- Canal b0 (sin gradiente) aporta menos informaciÃ³n direccional
- Reduce complejidad del modelo
- Enfoque en caracterÃ­sticas de difusiÃ³n pura

#### 2. Progressive Downsampling
**Estrategia**:
- Block 1: Mantener resoluciÃ³n completa (50Ã—96Ã—96)
- Blocks 2-3: MaxPool3D reduce a 12Ã—24Ã—24
- Block 4: Mantener resoluciÃ³n para features abstractos

**RazÃ³n**:
- Evita pÃ©rdida prematura de informaciÃ³n espacial
- Permite aprender tanto features locales (block1) como globales (block4)

#### 3. Regularization Stack
**TÃ©cnicas aplicadas**:
1. **Dropout3D (0.1)** en bloques convolucionales â†’ Previene co-adaptaciÃ³n de features
2. **BatchNorm3D** â†’ Estabiliza entrenamiento, permite learning rates mÃ¡s altos
3. **Dropout (0.2)** antes de clasificador â†’ RegularizaciÃ³n fuerte en capas densas
4. **Weight Decay (1e-4)** en optimizer â†’ PenalizaciÃ³n L2 implÃ­cita

**JustificaciÃ³n**: Dataset pequeÃ±o (200 samples) requiere regularizaciÃ³n agresiva

#### 4. Activation Functions
**ElecciÃ³n**: ReLU con `inplace=True`

**RazÃ³n**:
- ReLU: No sufre vanishing gradient, computacionalmente eficiente
- `inplace=True`: Ahorra memoria (crÃ­tico para volÃºmenes 3D grandes)

#### 5. Pooling Strategy
**AdaptiveAvgPool3D** vs MaxPool3D final:
- **MaxPool3D** en blocks intermedios â†’ Selecciona features mÃ¡s activados
- **AdaptiveAvgPool3D** al final â†’ Promedia informaciÃ³n espacial completa

---

## ğŸ¯ Training Strategy

### Loss Function: CrossEntropyLoss

Para clasificaciÃ³n binaria, PyTorch usa:

$$
\mathcal{L} = -\log\left(\frac{\exp(z_y)}{\sum_{c=1}^{C} \exp(z_c)}\right)
$$

Donde:
- $z_c$ = logit para clase $c$
- $y$ = clase verdadera

**Equivalente a**: Softmax + Negative Log-Likelihood

### Optimizer: Adam

**ParÃ¡metros**:
```python
optimizer = torch.optim.Adam(
    model.parameters(),
    lr=1e-4,
    betas=(0.9, 0.999),
    eps=1e-8,
    weight_decay=1e-4
)
```

**Adam update rule**:
$$
m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t
$$
$$
v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2
$$
$$
\theta_{t+1} = \theta_t - \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}
$$

### Early Stopping: Weighted Accuracy

**MÃ©trica de selecciÃ³n**:
$$
\text{Weighted Acc} = 0.4 \times \text{Train Acc} + 0.6 \times \text{Val Acc}
$$

**RazÃ³n**:
- Penaliza overfitting (val tiene mayor peso)
- Premia generalizaciÃ³n
- Mejor que usar solo val acc (puede ser ruidoso con pocas muestras)

---

## ğŸ“Š Evaluation Metrics

### Balanced Accuracy

Para datasets desbalanceados:

$$
\text{Balanced Acc} = \frac{1}{C} \sum_{c=1}^{C} \frac{TP_c}{TP_c + FN_c}
$$

Donde $C$ = nÃºmero de clases (2 en nuestro caso)

**Ventaja sobre accuracy estÃ¡ndar**:
- No favorece predicciÃ³n de clase mayoritaria
- Ãštil cuando clases tienen prevalencias diferentes
- En nuestro dataset: 130 controls vs 132 patients (casi balanceado, pero importante en validaciÃ³n)

### Confusion Matrix Interpretation

```
                Predicted
              Control  Patient
Actual Control   TN       FP
       Patient   FN       TP
```

**MÃ©tricas derivadas**:
- **Sensitivity (Recall)**: $\frac{TP}{TP + FN}$ â†’ % de pacientes correctamente identificados
- **Specificity**: $\frac{TN}{TN + FP}$ â†’ % de controles correctamente identificados
- **Precision**: $\frac{TP}{TP + FP}$ â†’ De los predichos como paciente, % que realmente lo son

**En contexto clÃ­nico**:
- Alta sensibilidad â†’ No perder pacientes (crÃ­tico en screening)
- Alta especificidad â†’ Evitar falsos positivos (reduce ansiedad y costos)

---

## ğŸ” Interpretability Analysis

### t-SNE: Visualizing Learned Representations

**t-SNE (t-Distributed Stochastic Neighbor Embedding)**:

Reduce embeddings de 256D (CNN) o 512D (SVM) a 2D preservando estructura local.

**Objetivo de optimizaciÃ³n**:
$$
\min \sum_{i \neq j} p_{ij} \log \frac{p_{ij}}{q_{ij}}
$$

Donde:
- $p_{ij}$ = similitud en espacio original (alta dimensiÃ³n)
- $q_{ij}$ = similitud en espacio 2D

**InterpretaciÃ³n en nuestro proyecto**:
- **Clusters separados** â†’ Modelo aprendiÃ³ features discriminativas
- **Puntos mezclados** â†’ Clases no son linealmente separables
- **Outliers** â†’ Casos difÃ­ciles o mala calidad de datos

### Activation Maps: What Does the CNN See?

**Grad-CAM (futuro trabajo)** puede localizar regiones cerebrales que el modelo usa para clasificaciÃ³n:

$$
L_{\text{Grad-CAM}}^c = \text{ReLU}\left(\sum_k \alpha_k^c A^k\right)
$$

Donde:
- $\alpha_k^c = \frac{1}{Z} \sum_{i,j,k} \frac{\partial y^c}{\partial A_{ijk}^k}$ = importancia del filtro $k$ para clase $c$
- $A^k$ = activation map del filtro $k$

---

## ğŸš€ Performance Optimization

### Memory Management for 3D Volumes

**Problema**: Volumen completo = 96Ã—96Ã—50Ã—64 Ã— 4 bytes (float32) â‰ˆ **113 MB por sujeto**

**Soluciones implementadas**:
1. **Batch size pequeÃ±o** (8) â†’ MÃ¡ximo 904 MB en GPU
2. **Dropout con inplace=True** â†’ Reutiliza memoria
3. **Gradient checkpointing** (no implementado aÃºn) â†’ Trade-off memoriaâ†”tiempo

### Data Loading Pipeline

```python
DataLoader(
    dataset,
    batch_size=8,
    shuffle=True,
    num_workers=2,     # Carga paralela
    pin_memory=True    # Acelera CPUâ†’GPU transfer
)
```

**pin_memory=True**: Pre-aloja datos en RAM pinned â†’ Transfer directo a GPU sin pasar por pageable memory (2-3Ã— mÃ¡s rÃ¡pido)



